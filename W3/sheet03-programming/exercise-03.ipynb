{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Momentum has been introduced in the lecture as a mechanism to speed up training.\n",
    "We would like to show this empirically in this exercise by an example on the MNIST dataset.\n",
    "We use a simple network architecture to classify handwritten digits into 10 different classes (0-9).\n",
    "\n",
    "Your task is to implement some parts of the training loop and study the effect of momentum with respect to the training speed.\n",
    "We compare training the model with Stochastic Gradient Descent (SGD) without momentum and with a momentum of `0.9`.\n",
    "To highlight that the effect is not the result of a specific hyperparameter choice, we train with different batch sizes and learning rates.\n",
    "For each of these configurations, we train two models: one with SGD and the other with SGD and momentum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data_root = './data'\n",
    "train_dataset = MNIST(data_root, train=True, download=True, transform=T.ToTensor())\n",
    "test_dataset = MNIST(data_root, train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing samples\n",
    "utils.show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function Implementation (20 P)\n",
    "\n",
    "**Task:** Implement the training function based on the predefined `train_one_epoch` function provided in `utils.py`.\n",
    "The training function receives a random initialized model and various hyperparameters. Your task is to\n",
    "implement the training loop given the function `train_one_epoch`. We want to optimize the model with a cross entropy loss.\n",
    "Further, we want to collect the final train and test accuracy and also how the training metrics progress over the training.\n",
    "\n",
    "\n",
    "Therefore, also return the train loss and accuracy after each epoch of the training for further analysis.\n",
    "\n",
    "*Hint:* to compute the final training and test accuracy after training, you can use the `accuracy` function from `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataset, test_dataset, epochs=10, batch_size=32, lr=0.01, momentum=0.0):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return train_acc, test_acc, arr_epoch_loss, arr_epoch_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for model training\n",
    "# with 1 epoch, the test accuracy should be ~80%.\n",
    "torch.manual_seed(1)\n",
    "model = utils.Lenet5()\n",
    "train(model=model, train_dataset=train_dataset, test_dataset=test_dataset, epochs=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with 1 epoch, the test accuracy should be ~96%.\n",
    "torch.manual_seed(1)\n",
    "model2 = utils.Lenet5()\n",
    "train(model=model2, train_dataset=train_dataset, test_dataset=test_dataset, epochs=1, momentum=0.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the effect of momentum with varying the value of learning rate (15 P)\n",
    "\n",
    "**Task:** We want to compare the effect of momentum on the optimization process for different learning rates.\n",
    "Use the previously created training function to implement the function `sweep_lr` which should train a model without momentum (`momentum=0.0`)\n",
    "and momentum (`momentum=0.9`). For each of the two trained models, plot the loss value after each epoch to study how the loss progresses during training.\n",
    "\n",
    "What can you observe from these plots? What influence does momentum have on the training and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sweep_lr(arr_lr, train_dataset, test_dataset, epochs=5):\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "sweep_lr([1e-3, 1e-2], train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the effect of momentum when varying the value of batch size (15 P)\n",
    "**Task:** We want to compare the effect of momentum on the optimization process for different batch sizes.\n",
    "Similar to the `sweep_lr` function, implement the function `sweep_batchsize` which should train a model without momentum (`momentum=0.0`)\n",
    "and momentum (`momentum=0.9`) with the specified batch size. For each of the two trained models, plot the loss value after each epoch to study how the loss progresses during training.\n",
    "\n",
    "What can you observe from these plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sweep_batchsize(arr_batchsize, train_dataset, test_dataset, epochs=5):\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "      \n",
    "sweep_batchsize([16, 32, 64], train_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
